#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨ç”Ÿæˆçš„lokiæ‰«æå™¨
ç”Ÿæˆæ—¶é—´: 2025-08-13T02:09:27.885214
åŸºäºæ¨¡å¼: loki_comprehensive
"""

import psutil
import time
import json
import logging
import re
import subprocess
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path


class LokiScanner:
    """lokiå¼‚å¸¸æ‰«æå™¨ - åŸºäºå¼‚å¸¸æ¨¡å¼æ£€æµ‹"""
    
    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–æ‰«æå™¨"""
        self.service_name = "loki"
        self.pattern_id = "loki_comprehensive"
        self.severity = "critical"
        self.confidence = 0.7
        
        # æ£€æµ‹é˜ˆå€¼ï¼ˆåŸºäºå¼‚å¸¸æ¨¡å¼ï¼‰
        self.thresholds = {}
        
        # æ—¥å¿—å…³é”®è¯ï¼ˆåŸºäºå¼‚å¸¸æ¨¡å¼ï¼‰
        self.error_keywords = [
        "185",
        "504",
        "132",
        "305",
        "502",
        "failed",
        "2025",
        "281",
        "192",
        "timeout",
        "318",
        "106",
        "334",
        "error",
        "503",
        "443",
        "500",
        "126",
        "107"
]
        
        # æ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.log_paths = [
        "/var/log/loki.log",
        "C:/logs/loki.log"
]
        
        # æ£€æµ‹è§„åˆ™ï¼ˆåŸºäºå¼‚å¸¸æ¨¡å¼ï¼‰
        self.detection_rules = [{'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 143', 'threshold': 143, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 143', 'severity': 'high'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.5', 'threshold': 0.5, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 50.00%', 'severity': 'high'}, {'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 143', 'threshold': 143, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 143', 'severity': 'high'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.5', 'threshold': 0.5, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 50.00%', 'severity': 'high'}, {'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 143', 'threshold': 143, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 143', 'severity': 'high'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.5', 'threshold': 0.5, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 50.00%', 'severity': 'high'}, {'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 143', 'threshold': 143, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 143', 'severity': 'high'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.5', 'threshold': 0.5, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 50.00%', 'severity': 'high'}, {'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 13', 'threshold': 13, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 13', 'severity': 'high'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.135', 'threshold': 0.135, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 13.50%', 'severity': 'high'}, {'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 69', 'threshold': 69, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 69', 'severity': 'critical'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.5', 'threshold': 0.5, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 50.00%', 'severity': 'critical'}, {'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 69', 'threshold': 69, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 69', 'severity': 'critical'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.5', 'threshold': 0.5, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 50.00%', 'severity': 'critical'}, {'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 69', 'threshold': 69, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 69', 'severity': 'critical'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.5', 'threshold': 0.5, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 50.00%', 'severity': 'critical'}, {'name': 'error_count_rule', 'metric': 'error_count', 'condition': 'error_count > 69', 'threshold': 69, 'description': 'é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: 69', 'severity': 'critical'}, {'name': 'error_rate_rule', 'metric': 'error_rate', 'condition': 'error_rate > 0.5', 'threshold': 0.5, 'description': 'é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: 50.00%', 'severity': 'critical'}]
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # æ‰«æç»“æœ
        self.scan_results = []
        
        # å¼‚å¸¸æ¨¡å¼ç»Ÿè®¡
        self.pattern_statistics = {
            'total_checks': 0,
            'anomalies_detected': 0,
            'pattern_matches': 0
        }
    
    def check_process_metrics(self) -> Dict[str, Any]:
        """æ£€æŸ¥è¿›ç¨‹æŒ‡æ ‡"""
        results = {
            'process_found': False,
            'metrics': {},
            'anomalies': [],
            'status': 'normal'
        }
        
        try:
            # æŸ¥æ‰¾ç›®æ ‡è¿›ç¨‹
            target_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                try:
                    if "loki" in proc.info['name'].lower():
                        target_processes.append(proc)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            if not target_processes:
                results['status'] = 'service_not_found'
                return results
            
            results['process_found'] = True
            
            # æ£€æŸ¥æ¯ä¸ªè¿›ç¨‹
            for proc in target_processes:
                try:
                    proc_info = proc.info
                    proc_obj = psutil.Process(proc_info['pid'])
                    
                    # è·å–è¯¦ç»†æŒ‡æ ‡
                    cpu_percent = proc_obj.cpu_percent()
                    memory_percent = proc_obj.memory_percent()
                    memory_rss = proc_obj.memory_info().rss
                    
                    try:
                        connections = len(proc_obj.connections())
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        connections = 0
                    
                    process_metrics = {
                        'pid': proc_info['pid'],
                        'name': proc_info['name'],
                        'cpu_percent': cpu_percent,
                        'memory_percent': memory_percent,
                        'memory_rss': memory_rss,
                        'connections': connections,
                        'status': proc_obj.status()
                    }
                    
                    results['metrics'][proc_info['pid']] = process_metrics
                    
                    # æ£€æŸ¥å¼‚å¸¸æ¡ä»¶
                    anomalies = self._check_metric_anomalies(process_metrics)
                    if anomalies:
                        results['anomalies'].extend(anomalies)
                        results['status'] = 'anomaly_detected'
                    
                except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                    self.logger.warning(f"æ— æ³•è®¿é—®è¿›ç¨‹ {proc_info.get('pid')}: {e}")
                    continue
        
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥è¿›ç¨‹æŒ‡æ ‡å¤±è´¥: {e}")
            results['status'] = 'check_failed'
        
        return results
    
    def check_system_metrics(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡"""
        results = {
            'metrics': {},
            'anomalies': [],
            'status': 'normal'
        }
        
        try:
            # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            net_connections = len(psutil.net_connections())
            
            system_metrics = {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'disk_usage_percent': disk.percent,
                'network_connections': net_connections,
                'timestamp': datetime.now().isoformat()
            }
            
            results['metrics'] = system_metrics
            
            # æ£€æŸ¥ç³»ç»Ÿå¼‚å¸¸
            anomalies = self._check_system_anomalies(system_metrics)
            if anomalies:
                results['anomalies'].extend(anomalies)
                results['status'] = 'anomaly_detected'
        
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
            results['status'] = 'check_failed'
        
        return results
    
    def check_log_anomalies(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ—¥å¿—å¼‚å¸¸"""
        results = {
            'logs_checked': [],
            'anomalies': [],
            'status': 'normal'
        }
        
        # ä¿å­˜æ—¥å¿—åˆ†æç»“æœä¾›å…¶ä»–æ–¹æ³•ä½¿ç”¨
        self.log_analysis_results = []
        
        for log_path in self.log_paths:
            try:
                if not Path(log_path).exists():
                    continue
                
                log_result = self._analyze_log_file(log_path)
                # ç²¾ç®€æ—¥å¿—ç»“æœï¼Œåªä¿ç•™å…³é”®ä¿¡æ¯
                simplified_log_result = {
                    'log_path': log_result.get('log_path', ''),
                    'lines_checked': log_result.get('lines_checked', 0),
                    'pattern_matches': log_result.get('pattern_matches', 0),
                    'status': log_result.get('status', 'unknown'),
                    'recent_errors_count': len(log_result.get('recent_errors', [])),
                    'anomalies_count': len(log_result.get('anomalies', []))
                }
                results['logs_checked'].append(simplified_log_result)
                self.log_analysis_results.append(simplified_log_result)
                
                if log_result.get('anomalies'):
                    results['anomalies'].extend(log_result['anomalies'])
                    results['status'] = 'anomaly_detected'
            
            except Exception as e:
                self.logger.error(f"åˆ†ææ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_path}: {e}")
        
        return results
    
    def _check_metric_anomalies(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºå¼‚å¸¸æ¨¡å¼æ£€æŸ¥æŒ‡æ ‡å¼‚å¸¸"""
        anomalies = []
        self.pattern_statistics['total_checks'] += 1
        
        # åŸºäºå¼‚å¸¸æ¨¡å¼çš„é˜ˆå€¼æ£€æŸ¥
        for metric_name, current_value in metrics.items():
            if metric_name in self.thresholds:
                threshold = self.thresholds[metric_name]
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
                if current_value > threshold:
                    anomaly = {
                        'type': f'{metric_name}_threshold_exceeded',
                        'metric': metric_name,
                        'current_value': current_value,
                        'threshold': threshold,
                        'severity': 'high' if current_value > threshold * 1.5 else 'medium',
                        'pattern_based': True,
                        'description': f'{metric_name} è¶…è¿‡å¼‚å¸¸æ¨¡å¼é˜ˆå€¼: {current_value} > {threshold}'
                    }
                    anomalies.append(anomaly)
                    self.pattern_statistics['anomalies_detected'] += 1
                    self.pattern_statistics['pattern_matches'] += 1
        
        # åŸºäºæ£€æµ‹è§„åˆ™çš„å¤åˆæ£€æŸ¥
        for rule in self.detection_rules:
            if self._evaluate_detection_rule(rule, metrics):
                anomaly = {
                    'type': 'pattern_rule_triggered',
                    'rule': rule.get('name', 'unknown'),
                    'severity': rule.get('severity', 'medium'),
                    'pattern_based': True,
                    'description': f'è§¦å‘å¼‚å¸¸æ¨¡å¼è§„åˆ™: {rule.get("description", "æœªçŸ¥è§„åˆ™")}'
                }
                anomalies.append(anomaly)
                self.pattern_statistics['anomalies_detected'] += 1
                self.pattern_statistics['pattern_matches'] += 1
        
        return anomalies
    
    def _evaluate_detection_rule(self, rule: Dict[str, Any], metrics: Dict[str, Any]) -> bool:
        """è¯„ä¼°æ£€æµ‹è§„åˆ™"""
        try:
            rule_type = rule.get('type', 'threshold')
            
            if rule_type == 'threshold':
                metric_name = rule.get('metric')
                threshold = rule.get('threshold')
                operator = rule.get('operator', '>')
                
                if metric_name in metrics:
                    current_value = metrics[metric_name]
                    
                    if operator == '>':
                        return current_value > threshold
                    elif operator == '<':
                        return current_value < threshold
                    elif operator == '>=':
                        return current_value >= threshold
                    elif operator == '<=':
                        return current_value <= threshold
                    elif operator == '==':
                        return current_value == threshold
            
            elif rule_type == 'composite':
                conditions = rule.get('conditions', [])
                logic = rule.get('logic', 'AND')
                
                if logic == 'AND':
                    return all(self._evaluate_detection_rule(cond, metrics) for cond in conditions)
                elif logic == 'OR':
                    return any(self._evaluate_detection_rule(cond, metrics) for cond in conditions)
            
            return False
            
        except Exception as e:
            self.logger.error(f"è¯„ä¼°æ£€æµ‹è§„åˆ™å¤±è´¥: {e}")
            return False
        
        return anomalies
    
    def _check_system_anomalies(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºå¼‚å¸¸æ¨¡å¼æ£€æŸ¥ç³»ç»Ÿå¼‚å¸¸"""
        return self._check_metric_anomalies(metrics)
    
    def _analyze_log_file(self, log_path: str) -> Dict[str, Any]:
        """åŸºäºå¼‚å¸¸æ¨¡å¼åˆ†ææ—¥å¿—æ–‡ä»¶"""
        result = {
            'log_path': log_path,
            'lines_checked': 0,
            'recent_errors': [],
            'anomalies': [],
            'pattern_matches': 0
        }
        
        try:
            if not Path(log_path).exists():
                result['status'] = 'file_not_found'
                return result
            
            # è¯»å–æœ€è¿‘çš„æ—¥å¿—è¡Œ
            with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
                result['lines_checked'] = len(lines)
                
                # æ£€æŸ¥æœ€è¿‘çš„1000è¡Œ
                recent_lines = lines[-1000:] if len(lines) > 1000 else lines
                
                for line in recent_lines:
                    # åŸºäºå¼‚å¸¸æ¨¡å¼çš„å…³é”®è¯æ£€æŸ¥ï¼ˆé™åˆ¶æ•°é‡ï¼‰
                    for keyword in self.error_keywords:
                        if keyword.lower() in line.lower():
                            error_info = {
                                'line': line.strip(),
                                'keyword': keyword,
                                'timestamp': datetime.now().isoformat(),
                                'pattern_based': True
                            }
                            result['recent_errors'].append(error_info)
                            result['pattern_matches'] += 1
                            
                            # é™åˆ¶é”™è¯¯è®°å½•æ•°é‡ï¼Œé¿å…æ–‡ä»¶è¿‡å¤§
                            if len(result['recent_errors']) >= 50:
                                break
                    
                    # åŸºäºå¼‚å¸¸æ¨¡å¼çš„æ¨¡å¼åŒ¹é…
                    for rule in self.detection_rules:
                        if rule.get('type') == 'log_pattern':
                            pattern = rule.get('pattern', '')
                            if pattern and re.search(pattern, line, re.IGNORECASE):
                                anomaly = {
                                    'type': 'log_pattern_match',
                                    'rule': rule.get('name', 'unknown'),
                                    'line': line.strip(),
                                    'pattern': pattern,
                                    'severity': rule.get('severity', 'medium'),
                                    'pattern_based': True,
                                    'description': f'æ—¥å¿—åŒ¹é…å¼‚å¸¸æ¨¡å¼: {rule.get("description", "æœªçŸ¥æ¨¡å¼")}'
                                }
                                result['anomalies'].append(anomaly)
                                result['pattern_matches'] += 1
            
            result['status'] = 'success'
            
        except Exception as e:
            self.logger.error(f"åˆ†ææ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_path}: {e}")
            result['status'] = 'error'
            result['error'] = str(e)
        
        return result
    
    def run_scan(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å¼‚å¸¸æ¨¡å¼æ‰«æ"""
        scan_start_time = datetime.now()
        
        self.logger.info(f"å¼€å§‹è¿è¡Œ loki å¼‚å¸¸æ¨¡å¼æ‰«æ...")
        
        # é‡ç½®ç»Ÿè®¡
        self.pattern_statistics = {
            'total_checks': 0,
            'anomalies_detected': 0,
            'pattern_matches': 0
        }
        
        scan_results = {
            'service_name': self.service_name,
            'pattern_id': self.pattern_id,
            'scan_start_time': scan_start_time.isoformat(),
            'scan_end_time': None,
            'pattern_statistics': self.pattern_statistics,
            'results': {}
        }
        
        try:
            # 1. æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡
            self.logger.info("æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡...")
            system_results = self.check_system_metrics()
            scan_results['results']['system_metrics'] = system_results
            
            # 2. æ£€æŸ¥è¿›ç¨‹æŒ‡æ ‡
            self.logger.info("æ£€æŸ¥è¿›ç¨‹æŒ‡æ ‡...")
            process_results = self.check_process_metrics()
            scan_results['results']['process_metrics'] = process_results
            
            # 3. æ£€æŸ¥æ—¥å¿—å¼‚å¸¸
            self.logger.info("æ£€æŸ¥æ—¥å¿—å¼‚å¸¸...")
            log_results = self.check_log_anomalies()
            scan_results['results']['log_anomalies'] = log_results
            
            # 4. ç”Ÿæˆå¼‚å¸¸åˆ†æ
            all_anomalies = []
            all_anomalies.extend(system_results.get('anomalies', []))
            all_anomalies.extend(process_results.get('anomalies', []))
            all_anomalies.extend(log_results.get('anomalies', []))
            
            # è®¡ç®—ä¸¥é‡ç¨‹åº¦è¯„åˆ†
            severity_score = self._calculate_severity_score(all_anomalies)
            
            # ç”Ÿæˆç²¾ç®€å¼‚å¸¸åˆ†ææ‘˜è¦
            anomaly_analysis = {
                'total_anomalies': len(all_anomalies),
                'severity_score': severity_score,
                'anomalies': all_anomalies[:10],  # åªä¿ç•™å‰10ä¸ªå¼‚å¸¸
                'pattern_based_detections': len([a for a in all_anomalies if a.get('pattern_based', False)]),
                'high_severity_count': len([a for a in all_anomalies if a.get('severity') == 'high']),
                'medium_severity_count': len([a for a in all_anomalies if a.get('severity') == 'medium']),
                'low_severity_count': len([a for a in all_anomalies if a.get('severity') == 'low'])
            }
            
            scan_results['results']['anomaly_analysis'] = anomaly_analysis
            
            # 5. ç”Ÿæˆæ‰«ææ‘˜è¦
            scan_results['summary'] = {
                'status': 'anomaly_detected' if all_anomalies else 'normal',
                'total_anomalies': len(all_anomalies),
                'severity_score': severity_score,
                'pattern_matches': self.pattern_statistics['pattern_matches'],
                'confidence': self.confidence,
                'recommendations': self._generate_recommendations(all_anomalies)
            }
            
        except Exception as e:
            self.logger.error(f"æ‰«æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            scan_results['error'] = str(e)
            scan_results['summary'] = {
                'status': 'scan_failed',
                'error': str(e)
            }
        
        scan_results['scan_end_time'] = datetime.now().isoformat()
        
        self.logger.info(f"loki æ‰«æå®Œæˆï¼Œå‘ç° {len(all_anomalies) if 'all_anomalies' in locals() else 0} ä¸ªå¼‚å¸¸")
        
        return scan_results
    
    def _calculate_severity_score(self, anomalies: List[Dict[str, Any]]) -> float:
        """è®¡ç®—ä¸¥é‡ç¨‹åº¦è¯„åˆ†"""
        if not anomalies:
            return 0.0
        
        score = 0.0
        for anomaly in anomalies:
            severity = anomaly.get('severity', 'medium')
            if severity == 'critical':
                score += 10.0
            elif severity == 'high':
                score += 7.0
            elif severity == 'medium':
                score += 4.0
            elif severity == 'low':
                score += 1.0
        
        # å½’ä¸€åŒ–åˆ°0-10åˆ†
        return min(10.0, score)
    
    def _generate_recommendations(self, anomalies: List[Dict[str, Any]]) -> List[str]:
        """åŸºäºå¼‚å¸¸ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if not anomalies:
            recommendations.append("ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œç»§ç»­ä¿æŒå½“å‰ç›‘æ§ç­–ç•¥")
            return recommendations
        
        # åŸºäºå¼‚å¸¸ç±»å‹ç”Ÿæˆå»ºè®®
        anomaly_types = [a.get('type', '') for a in anomalies]
        
        if 'cpu_threshold_exceeded' in anomaly_types:
            recommendations.append("CPUä½¿ç”¨ç‡å¼‚å¸¸ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½å’Œè¿›ç¨‹èµ„æºä½¿ç”¨æƒ…å†µ")
        
        if 'memory_threshold_exceeded' in anomaly_types:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡å¼‚å¸¸ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼å’Œä¼˜åŒ–å†…å­˜é…ç½®")
        
        if 'log_pattern_match' in anomaly_types:
            recommendations.append("æ—¥å¿—å¼‚å¸¸æ¨¡å¼æ£€æµ‹ï¼Œå»ºè®®æ£€æŸ¥æœåŠ¡é…ç½®å’Œé”™è¯¯æ—¥å¿—")
        
        if 'pattern_rule_triggered' in anomaly_types:
            recommendations.append("è§¦å‘å¼‚å¸¸æ¨¡å¼è§„åˆ™ï¼Œå»ºè®®æ ¹æ®è§„åˆ™æè¿°è¿›è¡Œç›¸åº”å¤„ç†")
        
        # é€šç”¨å»ºè®®
        if len(anomalies) > 5:
            recommendations.append("æ£€æµ‹åˆ°å¤šä¸ªå¼‚å¸¸ï¼Œå»ºè®®è¿›è¡Œå…¨é¢çš„ç³»ç»Ÿå¥åº·æ£€æŸ¥")
        
        return recommendations


def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰«æå™¨"""
    scanner = LokiScanner()
    
    try:
        results = scanner.run_scan()
        
        # è¾“å‡ºç»“æœ
        print(json.dumps(results, ensure_ascii=False, indent=2))
        
        # è¾“å‡ºæ‘˜è¦
        summary = results.get('summary', {})
        print(f"\nğŸ“Š æ‰«ææ‘˜è¦:")
        print(f"  çŠ¶æ€: {summary.get('status', 'unknown')}")
        print(f"  å¼‚å¸¸æ•°: {summary.get('total_anomalies', 0)}")
        print(f"  ä¸¥é‡åº¦è¯„åˆ†: {summary.get('severity_score', 0)}")
        print(f"  æ¨¡å¼åŒ¹é…: {summary.get('pattern_matches', 0)}")
        
        if 'recommendations' in summary:
            print(f"\nğŸ’¡ å»ºè®®:")
            for rec in summary['recommendations']:
                print(f"  - {rec}")
        
        # ä¿å­˜æ‰«æç»“æœåˆ°æ–‡ä»¶
        try:
            import os
            from pathlib import Path
            
            # ç¡®ä¿resultsç›®å½•å­˜åœ¨
            results_dir = Path(__file__).parent / "results"
            results_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"scan_results_loki_{timestamp}.json"
            filepath = results_dir / filename
            
            # ä¿å­˜ç»“æœ
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ æ‰«æç»“æœå·²ä¿å­˜åˆ°: {filepath}")
            
        except Exception as save_error:
            print(f"âš ï¸ ä¿å­˜æ‰«æç»“æœå¤±è´¥: {save_error}")
        
    except Exception as e:
        print(f"âŒ æ‰«æå¤±è´¥: {e}")


if __name__ == "__main__":
    main()