"""
ç»“æœè¾“å‡ºæ¨¡å—
è´Ÿè´£å°†åˆ†æç»“æœè¾“å‡ºåˆ°æ–‡ä»¶ä¸­
"""

import json
import os
import logging
from datetime import datetime
from typing import Dict, Any
import pandas as pd


class ResultExporter:
    """ç»“æœå¯¼å‡ºå™¨"""
    
    def __init__(self, results_dir: str = "./results"):
        self.results_dir = results_dir
        self.logger = logging.getLogger(__name__)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(results_dir, exist_ok=True)
        
    def _generate_filename(self, prefix: str, extension: str = "json") -> str:
        """ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{prefix}_{timestamp}.{extension}"
    
    def export_anomalies(self, anomalies_data: Dict, filename: str = None) -> str:
        """å¯¼å‡ºå¼‚å¸¸æ£€æµ‹ç»“æœ"""
        if filename is None:
            filename = self._generate_filename("anomalies")
        
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(anomalies_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"å¼‚å¸¸æ£€æµ‹ç»“æœå·²å¯¼å‡ºåˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºå¼‚å¸¸æ£€æµ‹ç»“æœå¤±è´¥: {str(e)}")
            raise
    
    def export_root_causes(self, root_cause_data: Dict, filename: str = None) -> str:
        """å¯¼å‡ºæ ¹å› åˆ†æç»“æœ"""
        if filename is None:
            filename = self._generate_filename("root_causes")
        
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(root_cause_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"æ ¹å› åˆ†æç»“æœå·²å¯¼å‡ºåˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºæ ¹å› åˆ†æç»“æœå¤±è´¥: {str(e)}")
            raise
    
    def export_ai_analysis(self, ai_analysis_data: Dict, filename: str = None) -> str:
        """å¯¼å‡ºAIåˆ†æç»“æœ"""
        if filename is None:
            filename = self._generate_filename("ai_analysis")
        
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(ai_analysis_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"AIåˆ†æç»“æœå·²å¯¼å‡ºåˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºAIåˆ†æç»“æœå¤±è´¥: {str(e)}")
            raise
    
    def export_comprehensive_report(self, all_data: Dict, filename: str = None) -> str:
        """å¯¼å‡ºç»¼åˆæŠ¥å‘Š"""
        if filename is None:
            filename = self._generate_filename("comprehensive_report")
        
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(all_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"ç»¼åˆæŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºç»¼åˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
            raise
    
    def export_summary_report(self, all_data: Dict, filename: str = None) -> str:
        """å¯¼å‡ºæ‘˜è¦æŠ¥å‘Šï¼ˆäººç±»å¯è¯»æ ¼å¼ï¼‰"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"summary_report_{timestamp}.txt"
        
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                self._write_summary_report(f, all_data)
            
            self.logger.info(f"æ‘˜è¦æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºæ‘˜è¦æŠ¥å‘Šå¤±è´¥: {str(e)}")
            raise
    
    def _write_summary_report(self, file, all_data: Dict):
        """å†™å…¥æ‘˜è¦æŠ¥å‘Šå†…å®¹"""
        file.write("=" * 80 + "\n")
        file.write("å¾®æœåŠ¡å¼‚å¸¸æ£€æµ‹ä¸æ ¹å› åˆ†ææŠ¥å‘Š\n")
        file.write("=" * 80 + "\n\n")
        
        # åŸºæœ¬ä¿¡æ¯
        file.write("ğŸ• æŠ¥å‘Šç”Ÿæˆæ—¶é—´: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n")
        
        skywalking_data = all_data.get("skywalking_data", {})
        if skywalking_data:
            file.write(f"ğŸ“Š æ•°æ®é‡‡é›†æ—¶é—´: {skywalking_data.get('timestamp', 'N/A')}\n")
            file.write(f"ğŸ” ç›‘æ§æœåŠ¡æ•°é‡: {len(skywalking_data.get('services', []))}\n")
        
        file.write("\n" + "=" * 50 + "\n")
        file.write("å¼‚å¸¸æ£€æµ‹ç»“æœ\n")
        file.write("=" * 50 + "\n\n")
        
        # å¼‚å¸¸æ£€æµ‹ç»“æœ
        anomalies_data = all_data.get("anomalies_data", {})
        if anomalies_data:
            anomalies = anomalies_data.get("anomalies", {})
            high_priority = anomalies.get("high_priority", [])
            medium_priority = anomalies.get("medium_priority", [])
            low_priority = anomalies.get("low_priority", [])
            
            total_anomalies = len(high_priority) + len(medium_priority) + len(low_priority)
            
            file.write(f"ğŸ“ˆ æ£€æµ‹åˆ°å¼‚å¸¸æ€»æ•°: {total_anomalies}\n")
            file.write(f"ğŸ”´ é«˜ä¼˜å…ˆçº§å¼‚å¸¸: {len(high_priority)}\n")
            file.write(f"ğŸŸ¡ ä¸­ä¼˜å…ˆçº§å¼‚å¸¸: {len(medium_priority)}\n")
            file.write(f"ğŸŸ¢ ä½ä¼˜å…ˆçº§å¼‚å¸¸: {len(low_priority)}\n\n")
            
            # é«˜ä¼˜å…ˆçº§å¼‚å¸¸è¯¦æƒ…
            if high_priority:
                file.write("ğŸ”´ é«˜ä¼˜å…ˆçº§å¼‚å¸¸è¯¦æƒ…:\n")
                file.write("-" * 40 + "\n")
                for i, anomaly in enumerate(high_priority, 1):
                    file.write(f"{i}. æœåŠ¡: {anomaly.get('service', 'unknown')}\n")
                    file.write(f"   ç±»å‹: {anomaly.get('type', 'unknown')}\n")
                    file.write(f"   æè¿°: {anomaly.get('description', 'unknown')}\n")
                    if 'value' in anomaly:
                        file.write(f"   æ•°å€¼: {anomaly['value']}\n")
                    file.write("\n")
            
            # ä¸­ä¼˜å…ˆçº§å¼‚å¸¸è¯¦æƒ…
            if medium_priority:
                file.write("ğŸŸ¡ ä¸­ä¼˜å…ˆçº§å¼‚å¸¸è¯¦æƒ…:\n")
                file.write("-" * 40 + "\n")
                for i, anomaly in enumerate(medium_priority[:5], 1):  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    file.write(f"{i}. æœåŠ¡: {anomaly.get('service', 'unknown')}\n")
                    file.write(f"   ç±»å‹: {anomaly.get('type', 'unknown')}\n")
                    file.write(f"   æè¿°: {anomaly.get('description', 'unknown')}\n\n")
                
                if len(medium_priority) > 5:
                    file.write(f"   ... è¿˜æœ‰ {len(medium_priority) - 5} ä¸ªä¸­ä¼˜å…ˆçº§å¼‚å¸¸\n\n")
        
        file.write("\n" + "=" * 50 + "\n")
        file.write("æ ¹å› åˆ†æç»“æœ\n")
        file.write("=" * 50 + "\n\n")
        
        # æ ¹å› åˆ†æç»“æœ
        root_cause_data = all_data.get("root_cause_data", {})
        if root_cause_data:
            root_causes = root_cause_data.get("root_causes", [])
            
            file.write(f"ğŸ¯ è¯†åˆ«æ ¹å› æ•°é‡: {len(root_causes)}\n\n")
            
            if root_causes:
                file.write("ğŸ¯ æ ¹å› åˆ†æè¯¦æƒ…:\n")
                file.write("-" * 40 + "\n")
                
                for i, root_cause in enumerate(root_causes[:3], 1):  # æ˜¾ç¤ºå‰3ä¸ªæ ¹å› 
                    file.write(f"{i}. æ ¹å› æœåŠ¡: {root_cause.get('root_service', 'unknown')}\n")
                    file.write(f"   æ ¹å› å¾—åˆ†: {root_cause.get('root_cause_score', 0):.2f}\n")
                    file.write(f"   ç½®ä¿¡åº¦: {root_cause.get('confidence', 0):.2f}\n")
                    
                    anomalies = root_cause.get('anomalies', [])
                    if anomalies:
                        file.write(f"   ç›¸å…³å¼‚å¸¸æ•°: {len(anomalies)}\n")
                        anomaly_types = list(set(anomaly.get('type', '') for anomaly in anomalies))
                        file.write(f"   å¼‚å¸¸ç±»å‹: {', '.join(anomaly_types[:3])}\n")
                    
                    impact = root_cause.get('impact_analysis', {})
                    affected_services = impact.get('affected_services', [])
                    if affected_services:
                        file.write(f"   å½±å“æœåŠ¡æ•°: {len(affected_services)}\n")
                        file.write(f"   å½±å“ä¸¥é‡ç¨‹åº¦: {impact.get('impact_severity', 'unknown')}\n")
                    
                    recommendation = root_cause.get('recommendation', '')
                    if recommendation:
                        file.write(f"   å»ºè®®æªæ–½: {recommendation}\n")
                    
                    file.write("\n")
                
                if len(root_causes) > 3:
                    file.write(f"   ... è¿˜æœ‰ {len(root_causes) - 3} ä¸ªæ ¹å› \n\n")
        
        file.write("\n" + "=" * 50 + "\n")
        file.write("AIæ™ºèƒ½åˆ†æ\n")
        file.write("=" * 50 + "\n\n")
        
        # AIåˆ†æç»“æœ
        ai_analysis = all_data.get("ai_analysis", {})
        if ai_analysis:
            # å¼‚å¸¸åˆ†æ
            anomaly_analysis = ai_analysis.get("anomaly_analysis", {})
            if anomaly_analysis and anomaly_analysis.get("success"):
                file.write("ğŸ¤– å¼‚å¸¸æ™ºèƒ½åˆ†æ:\n")
                file.write("-" * 40 + "\n")
                ai_response = anomaly_analysis.get("ai_analysis", "")
                if ai_response:
                    file.write(ai_response + "\n\n")
            
            # æ ¹å› åˆ†æ
            root_cause_analysis = ai_analysis.get("root_cause_analysis", {})
            if root_cause_analysis and root_cause_analysis.get("success"):
                file.write("ğŸ¤– æ ¹å› æ™ºèƒ½åˆ†æ:\n")
                file.write("-" * 40 + "\n")
                ai_response = root_cause_analysis.get("ai_analysis", "")
                if ai_response:
                    file.write(ai_response + "\n\n")
            
            # ç»¼åˆæŠ¥å‘Š
            comprehensive_report = ai_analysis.get("comprehensive_report", {})
            if comprehensive_report and comprehensive_report.get("success"):
                file.write("ğŸ¤– ç»¼åˆæ™ºèƒ½æŠ¥å‘Š:\n")
                file.write("-" * 40 + "\n")
                ai_report = comprehensive_report.get("ai_report", "")
                if ai_report:
                    file.write(ai_report + "\n\n")
        
        file.write("\n" + "=" * 50 + "\n")
        file.write("æŠ€æœ¯ç»Ÿè®¡ä¿¡æ¯\n")
        file.write("=" * 50 + "\n\n")
        
        # æŠ€æœ¯ç»Ÿè®¡
        if skywalking_data:
            topology = skywalking_data.get('topology', {})
            file.write(f"ğŸ”— æœåŠ¡æ‹“æ‰‘èŠ‚ç‚¹æ•°: {len(topology.get('nodes', []))}\n")
            file.write(f"ğŸ”— æœåŠ¡è°ƒç”¨å…³ç³»æ•°: {len(topology.get('calls', []))}\n")
        
        if root_cause_data:
            graph_stats = root_cause_data.get('service_graph_stats', {})
            file.write(f"ğŸ“Š åˆ†æå›¾èŠ‚ç‚¹æ•°: {graph_stats.get('nodes', 0)}\n")
            file.write(f"ğŸ“Š åˆ†æå›¾è¾¹æ•°: {graph_stats.get('edges', 0)}\n")
        
        file.write("\n" + "=" * 80 + "\n")
        file.write("æŠ¥å‘Šç»“æŸ\n")
        file.write("=" * 80 + "\n")
    
    def export_csv_summary(self, all_data: Dict, filename: str = None) -> str:
        """å¯¼å‡ºCSVæ ¼å¼çš„æ‘˜è¦æ•°æ®"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"anomalies_summary_{timestamp}.csv"
        
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            # æå–å¼‚å¸¸æ•°æ®
            anomalies_data = all_data.get("anomalies_data", {})
            all_anomalies = []
            
            for priority, anomalies in anomalies_data.get("anomalies", {}).items():
                for anomaly in anomalies:
                    anomaly_record = {
                        "priority": priority,
                        "service": anomaly.get("service", ""),
                        "type": anomaly.get("type", ""),
                        "severity": anomaly.get("severity", ""),
                        "description": anomaly.get("description", ""),
                        "value": anomaly.get("value", ""),
                        "threshold": anomaly.get("threshold", ""),
                        "detection_timestamp": anomalies_data.get("detection_timestamp", "")
                    }
                    all_anomalies.append(anomaly_record)
            
            if all_anomalies:
                df = pd.DataFrame(all_anomalies)
                df.to_csv(filepath, index=False, encoding='utf-8-sig')
                self.logger.info(f"CSVæ‘˜è¦å·²å¯¼å‡ºåˆ°: {filepath}")
            else:
                self.logger.warning("æ²¡æœ‰å¼‚å¸¸æ•°æ®å¯å¯¼å‡ºä¸ºCSV")
            
            return filepath
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºCSVæ‘˜è¦å¤±è´¥: {str(e)}")
            raise
    
    def export_all(self, skywalking_data: Dict, anomalies_data: Dict, 
                   root_cause_data: Dict, ai_analysis: Dict) -> Dict[str, str]:
        """å¯¼å‡ºæ‰€æœ‰ç»“æœ"""
        exported_files = {}
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        all_data = {
            "skywalking_data": skywalking_data,
            "anomalies_data": anomalies_data,
            "root_cause_data": root_cause_data,
            "ai_analysis": ai_analysis,
            "export_timestamp": datetime.now().isoformat()
        }
        
        try:
            # å¯¼å‡ºå„ä¸ªç»„ä»¶çš„ç»“æœ
            exported_files["anomalies"] = self.export_anomalies(anomalies_data)
            exported_files["root_causes"] = self.export_root_causes(root_cause_data)
            exported_files["ai_analysis"] = self.export_ai_analysis(ai_analysis)
            exported_files["comprehensive_report"] = self.export_comprehensive_report(all_data)
            exported_files["summary_report"] = self.export_summary_report(all_data)
            exported_files["csv_summary"] = self.export_csv_summary(all_data)
            
            # åˆ›å»ºç´¢å¼•æ–‡ä»¶
            index_filename = self._generate_filename("index", "txt")
            index_filepath = os.path.join(self.results_dir, index_filename)
            
            with open(index_filepath, 'w', encoding='utf-8') as f:
                f.write("å¾®æœåŠ¡å¼‚å¸¸æ£€æµ‹ä¸æ ¹å› åˆ†æ - æ–‡ä»¶ç´¢å¼•\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                for file_type, filepath in exported_files.items():
                    filename = os.path.basename(filepath)
                    f.write(f"{file_type}: {filename}\n")
            
            exported_files["index"] = index_filepath
            
            self.logger.info(f"æ‰€æœ‰ç»“æœå·²å¯¼å‡ºï¼Œå…± {len(exported_files)} ä¸ªæ–‡ä»¶")
            return exported_files
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºæ‰€æœ‰ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
