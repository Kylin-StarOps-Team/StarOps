#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰«æå™¨ç”Ÿæˆæ¨¡å— - æ ¹æ®å¼‚å¸¸æ¨¡å¼è‡ªåŠ¨ç”Ÿæˆæ£€æµ‹è„šæœ¬
"""

import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
from jinja2 import Template


class ScannerGenerator:
    """æ‰«æå™¨ä»£ç ç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "data", scanners_dir: str = "/home/denerate/abnormal_pattern_detect/scanners"):
        """åˆå§‹åŒ–æ‰«æå™¨ç”Ÿæˆå™¨"""
        self.output_dir = Path(output_dir)
        self.scanners_dir = Path(scanners_dir)
        self.scanners_dir.mkdir(exist_ok=True)
        
        # è¾“å…¥æ–‡ä»¶
        self.patterns_file = self.output_dir / "extracted_patterns.json"
        
        # æ‰«æå™¨æ¨¡æ¿
        self.scanner_templates = self._load_scanner_templates()
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def _load_scanner_templates(self) -> Dict[str, str]:
        """åŠ è½½æ‰«æå™¨æ¨¡æ¿"""
        templates = {}
        
        # åŸºç¡€æ‰«æå™¨æ¨¡æ¿
        templates['base_scanner'] = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨ç”Ÿæˆçš„{{ service_name }}æ‰«æå™¨
ç”Ÿæˆæ—¶é—´: {{ generation_time }}
åŸºäºæ¨¡å¼: {{ pattern_id }}
"""

import psutil
import time
import json
import logging
import re
import subprocess
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path


class {{ class_name }}Scanner:
    """{{ service_name }}å¼‚å¸¸æ‰«æå™¨ - åŸºäºå¼‚å¸¸æ¨¡å¼æ£€æµ‹"""
    
    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–æ‰«æå™¨"""
        self.service_name = "{{ service_name }}"
        self.pattern_id = "{{ pattern_id }}"
        self.severity = "{{ severity }}"
        self.confidence = {{ confidence }}
        
        # æ£€æµ‹é˜ˆå€¼ï¼ˆåŸºäºå¼‚å¸¸æ¨¡å¼ï¼‰
        self.thresholds = {{ thresholds }}
        
        # æ—¥å¿—å…³é”®è¯ï¼ˆåŸºäºå¼‚å¸¸æ¨¡å¼ï¼‰
        self.error_keywords = {{ error_keywords }}
        
        # æ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.log_paths = {{ log_paths }}
        
        # æ£€æµ‹è§„åˆ™ï¼ˆåŸºäºå¼‚å¸¸æ¨¡å¼ï¼‰
        self.detection_rules = {{ detection_rules }}
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # æ‰«æç»“æœ
        self.scan_results = []
        
        # å¼‚å¸¸æ¨¡å¼ç»Ÿè®¡
        self.pattern_statistics = {
            'total_checks': 0,
            'anomalies_detected': 0,
            'pattern_matches': 0
        }
    
    def check_process_metrics(self) -> Dict[str, Any]:
        """æ£€æŸ¥è¿›ç¨‹æŒ‡æ ‡"""
        results = {
            'process_found': False,
            'metrics': {},
            'anomalies': [],
            'status': 'normal'
        }
        
        try:
            # æŸ¥æ‰¾ç›®æ ‡è¿›ç¨‹
            target_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                try:
                    if "{{ service_name }}" in proc.info['name'].lower():
                        target_processes.append(proc)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            if not target_processes:
                results['status'] = 'service_not_found'
                return results
            
            results['process_found'] = True
            
            # æ£€æŸ¥æ¯ä¸ªè¿›ç¨‹
            for proc in target_processes:
                try:
                    proc_info = proc.info
                    proc_obj = psutil.Process(proc_info['pid'])
                    
                    # è·å–è¯¦ç»†æŒ‡æ ‡
                    cpu_percent = proc_obj.cpu_percent()
                    memory_percent = proc_obj.memory_percent()
                    memory_rss = proc_obj.memory_info().rss
                    
                    try:
                        connections = len(proc_obj.connections())
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        connections = 0
                    
                    process_metrics = {
                        'pid': proc_info['pid'],
                        'name': proc_info['name'],
                        'cpu_percent': cpu_percent,
                        'memory_percent': memory_percent,
                        'memory_rss': memory_rss,
                        'connections': connections,
                        'status': proc_obj.status()
                    }
                    
                    results['metrics'][proc_info['pid']] = process_metrics
                    
                    # æ£€æŸ¥å¼‚å¸¸æ¡ä»¶
                    anomalies = self._check_metric_anomalies(process_metrics)
                    if anomalies:
                        results['anomalies'].extend(anomalies)
                        results['status'] = 'anomaly_detected'
                    
                except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                    self.logger.warning(f"æ— æ³•è®¿é—®è¿›ç¨‹ {proc_info.get('pid')}: {e}")
                    continue
        
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥è¿›ç¨‹æŒ‡æ ‡å¤±è´¥: {e}")
            results['status'] = 'check_failed'
        
        return results
    
    def check_system_metrics(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡"""
        results = {
            'metrics': {},
            'anomalies': [],
            'status': 'normal'
        }
        
        try:
            # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            net_connections = len(psutil.net_connections())
            
            system_metrics = {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'disk_usage_percent': disk.percent,
                'network_connections': net_connections,
                'timestamp': datetime.now().isoformat()
            }
            
            results['metrics'] = system_metrics
            
            # æ£€æŸ¥ç³»ç»Ÿå¼‚å¸¸
            anomalies = self._check_system_anomalies(system_metrics)
            if anomalies:
                results['anomalies'].extend(anomalies)
                results['status'] = 'anomaly_detected'
        
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
            results['status'] = 'check_failed'
        
        return results
    
    def check_log_anomalies(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ—¥å¿—å¼‚å¸¸"""
        results = {
            'logs_checked': [],
            'anomalies': [],
            'status': 'normal'
        }
        
        # ä¿å­˜æ—¥å¿—åˆ†æç»“æœä¾›å…¶ä»–æ–¹æ³•ä½¿ç”¨
        self.log_analysis_results = []
        
        for log_path in self.log_paths:
            try:
                if not Path(log_path).exists():
                    continue
                
                log_result = self._analyze_log_file(log_path)
                # ç²¾ç®€æ—¥å¿—ç»“æœï¼Œåªä¿ç•™å…³é”®ä¿¡æ¯
                simplified_log_result = {
                    'log_path': log_result.get('log_path', ''),
                    'lines_checked': log_result.get('lines_checked', 0),
                    'pattern_matches': log_result.get('pattern_matches', 0),
                    'status': log_result.get('status', 'unknown'),
                    'recent_errors_count': len(log_result.get('recent_errors', [])),
                    'anomalies_count': len(log_result.get('anomalies', []))
                }
                results['logs_checked'].append(simplified_log_result)
                self.log_analysis_results.append(simplified_log_result)
                
                if log_result.get('anomalies'):
                    results['anomalies'].extend(log_result['anomalies'])
                    results['status'] = 'anomaly_detected'
            
            except Exception as e:
                self.logger.error(f"åˆ†ææ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_path}: {e}")
        
        return results
    
    def _check_metric_anomalies(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºå¼‚å¸¸æ¨¡å¼æ£€æŸ¥æŒ‡æ ‡å¼‚å¸¸"""
        anomalies = []
        self.pattern_statistics['total_checks'] += 1
        
        # åŸºäºå¼‚å¸¸æ¨¡å¼çš„é˜ˆå€¼æ£€æŸ¥
        for metric_name, current_value in metrics.items():
            if metric_name in self.thresholds:
                threshold = self.thresholds[metric_name]
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
                if current_value > threshold:
                    anomaly = {
                        'type': f'{metric_name}_threshold_exceeded',
                        'metric': metric_name,
                        'current_value': current_value,
                        'threshold': threshold,
                        'severity': 'high' if current_value > threshold * 1.5 else 'medium',
                        'pattern_based': True,
                        'description': f'{metric_name} è¶…è¿‡å¼‚å¸¸æ¨¡å¼é˜ˆå€¼: {current_value} > {threshold}'
                    }
                    anomalies.append(anomaly)
                    self.pattern_statistics['anomalies_detected'] += 1
                    self.pattern_statistics['pattern_matches'] += 1
        
        # åŸºäºæ£€æµ‹è§„åˆ™çš„å¤åˆæ£€æŸ¥
        for rule in self.detection_rules:
            if self._evaluate_detection_rule(rule, metrics):
                anomaly = {
                    'type': 'pattern_rule_triggered',
                    'rule': rule.get('name', 'unknown'),
                    'severity': rule.get('severity', 'medium'),
                    'pattern_based': True,
                    'description': f'è§¦å‘å¼‚å¸¸æ¨¡å¼è§„åˆ™: {rule.get("description", "æœªçŸ¥è§„åˆ™")}'
                }
                anomalies.append(anomaly)
                self.pattern_statistics['anomalies_detected'] += 1
                self.pattern_statistics['pattern_matches'] += 1
        
        return anomalies
    
    def _evaluate_detection_rule(self, rule: Dict[str, Any], metrics: Dict[str, Any]) -> bool:
        """è¯„ä¼°æ£€æµ‹è§„åˆ™"""
        try:
            rule_type = rule.get('type', 'threshold')
            
            if rule_type == 'threshold':
                metric_name = rule.get('metric')
                threshold = rule.get('threshold')
                operator = rule.get('operator', '>')
                
                if metric_name in metrics:
                    current_value = metrics[metric_name]
                    
                    if operator == '>':
                        return current_value > threshold
                    elif operator == '<':
                        return current_value < threshold
                    elif operator == '>=':
                        return current_value >= threshold
                    elif operator == '<=':
                        return current_value <= threshold
                    elif operator == '==':
                        return current_value == threshold
            
            elif rule_type == 'composite':
                conditions = rule.get('conditions', [])
                logic = rule.get('logic', 'AND')
                
                if logic == 'AND':
                    return all(self._evaluate_detection_rule(cond, metrics) for cond in conditions)
                elif logic == 'OR':
                    return any(self._evaluate_detection_rule(cond, metrics) for cond in conditions)
            
            return False
            
        except Exception as e:
            self.logger.error(f"è¯„ä¼°æ£€æµ‹è§„åˆ™å¤±è´¥: {e}")
            return False
        
        return anomalies
    
    def _check_system_anomalies(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºå¼‚å¸¸æ¨¡å¼æ£€æŸ¥ç³»ç»Ÿå¼‚å¸¸"""
        return self._check_metric_anomalies(metrics)
    
    def _analyze_log_file(self, log_path: str) -> Dict[str, Any]:
        """åŸºäºå¼‚å¸¸æ¨¡å¼åˆ†ææ—¥å¿—æ–‡ä»¶"""
        result = {
            'log_path': log_path,
            'lines_checked': 0,
            'recent_errors': [],
            'anomalies': [],
            'pattern_matches': 0
        }
        
        try:
            if not Path(log_path).exists():
                result['status'] = 'file_not_found'
                return result
            
            # è¯»å–æœ€è¿‘çš„æ—¥å¿—è¡Œ
            with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
                result['lines_checked'] = len(lines)
                
                # æ£€æŸ¥æœ€è¿‘çš„1000è¡Œ
                recent_lines = lines[-1000:] if len(lines) > 1000 else lines
                
                for line in recent_lines:
                    # åŸºäºå¼‚å¸¸æ¨¡å¼çš„å…³é”®è¯æ£€æŸ¥ï¼ˆé™åˆ¶æ•°é‡ï¼‰
                    for keyword in self.error_keywords:
                        if keyword.lower() in line.lower():
                            error_info = {
                                'line': line.strip(),
                                'keyword': keyword,
                                'timestamp': datetime.now().isoformat(),
                                'pattern_based': True
                            }
                            result['recent_errors'].append(error_info)
                            result['pattern_matches'] += 1
                            
                            # é™åˆ¶é”™è¯¯è®°å½•æ•°é‡ï¼Œé¿å…æ–‡ä»¶è¿‡å¤§
                            if len(result['recent_errors']) >= 50:
                                break
                    
                    # åŸºäºå¼‚å¸¸æ¨¡å¼çš„æ¨¡å¼åŒ¹é…
                    for rule in self.detection_rules:
                        if rule.get('type') == 'log_pattern':
                            pattern = rule.get('pattern', '')
                            if pattern and re.search(pattern, line, re.IGNORECASE):
                                anomaly = {
                                    'type': 'log_pattern_match',
                                    'rule': rule.get('name', 'unknown'),
                                    'line': line.strip(),
                                    'pattern': pattern,
                                    'severity': rule.get('severity', 'medium'),
                                    'pattern_based': True,
                                    'description': f'æ—¥å¿—åŒ¹é…å¼‚å¸¸æ¨¡å¼: {rule.get("description", "æœªçŸ¥æ¨¡å¼")}'
                                }
                                result['anomalies'].append(anomaly)
                                result['pattern_matches'] += 1
            
            result['status'] = 'success'
            
        except Exception as e:
            self.logger.error(f"åˆ†ææ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_path}: {e}")
            result['status'] = 'error'
            result['error'] = str(e)
        
        return result
    
    def run_scan(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å¼‚å¸¸æ¨¡å¼æ‰«æ"""
        scan_start_time = datetime.now()
        
        self.logger.info(f"å¼€å§‹è¿è¡Œ {{ service_name }} å¼‚å¸¸æ¨¡å¼æ‰«æ...")
        
        # é‡ç½®ç»Ÿè®¡
        self.pattern_statistics = {
            'total_checks': 0,
            'anomalies_detected': 0,
            'pattern_matches': 0
        }
        
        scan_results = {
            'service_name': self.service_name,
            'pattern_id': self.pattern_id,
            'scan_start_time': scan_start_time.isoformat(),
            'scan_end_time': None,
            'pattern_statistics': self.pattern_statistics,
            'results': {}
        }
        
        try:
            # 1. æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡
            self.logger.info("æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡...")
            system_results = self.check_system_metrics()
            scan_results['results']['system_metrics'] = system_results
            
            # 2. æ£€æŸ¥è¿›ç¨‹æŒ‡æ ‡
            self.logger.info("æ£€æŸ¥è¿›ç¨‹æŒ‡æ ‡...")
            process_results = self.check_process_metrics()
            scan_results['results']['process_metrics'] = process_results
            
            # 3. æ£€æŸ¥æ—¥å¿—å¼‚å¸¸
            self.logger.info("æ£€æŸ¥æ—¥å¿—å¼‚å¸¸...")
            log_results = self.check_log_anomalies()
            scan_results['results']['log_anomalies'] = log_results
            
            # 4. ç”Ÿæˆå¼‚å¸¸åˆ†æ
            all_anomalies = []
            all_anomalies.extend(system_results.get('anomalies', []))
            all_anomalies.extend(process_results.get('anomalies', []))
            all_anomalies.extend(log_results.get('anomalies', []))
            
            # è®¡ç®—ä¸¥é‡ç¨‹åº¦è¯„åˆ†
            severity_score = self._calculate_severity_score(all_anomalies)
            
            # ç”Ÿæˆç²¾ç®€å¼‚å¸¸åˆ†ææ‘˜è¦
            anomaly_analysis = {
                'total_anomalies': len(all_anomalies),
                'severity_score': severity_score,
                'anomalies': all_anomalies[:10],  # åªä¿ç•™å‰10ä¸ªå¼‚å¸¸
                'pattern_based_detections': len([a for a in all_anomalies if a.get('pattern_based', False)]),
                'high_severity_count': len([a for a in all_anomalies if a.get('severity') == 'high']),
                'medium_severity_count': len([a for a in all_anomalies if a.get('severity') == 'medium']),
                'low_severity_count': len([a for a in all_anomalies if a.get('severity') == 'low'])
            }
            
            scan_results['results']['anomaly_analysis'] = anomaly_analysis
            
            # 5. ç”Ÿæˆæ‰«ææ‘˜è¦
            scan_results['summary'] = {
                'status': 'anomaly_detected' if all_anomalies else 'normal',
                'total_anomalies': len(all_anomalies),
                'severity_score': severity_score,
                'pattern_matches': self.pattern_statistics['pattern_matches'],
                'confidence': self.confidence,
                'recommendations': self._generate_recommendations(all_anomalies)
            }
            
        except Exception as e:
            self.logger.error(f"æ‰«æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            scan_results['error'] = str(e)
            scan_results['summary'] = {
                'status': 'scan_failed',
                'error': str(e)
            }
        
        scan_results['scan_end_time'] = datetime.now().isoformat()
        
        self.logger.info(f"{{ service_name }} æ‰«æå®Œæˆï¼Œå‘ç° {len(all_anomalies) if 'all_anomalies' in locals() else 0} ä¸ªå¼‚å¸¸")
        
        return scan_results
    
    def _calculate_severity_score(self, anomalies: List[Dict[str, Any]]) -> float:
        """è®¡ç®—ä¸¥é‡ç¨‹åº¦è¯„åˆ†"""
        if not anomalies:
            return 0.0
        
        score = 0.0
        for anomaly in anomalies:
            severity = anomaly.get('severity', 'medium')
            if severity == 'critical':
                score += 10.0
            elif severity == 'high':
                score += 7.0
            elif severity == 'medium':
                score += 4.0
            elif severity == 'low':
                score += 1.0
        
        # å½’ä¸€åŒ–åˆ°0-10åˆ†
        return min(10.0, score)
    
    def _generate_recommendations(self, anomalies: List[Dict[str, Any]]) -> List[str]:
        """åŸºäºå¼‚å¸¸ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if not anomalies:
            recommendations.append("ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œç»§ç»­ä¿æŒå½“å‰ç›‘æ§ç­–ç•¥")
            return recommendations
        
        # åŸºäºå¼‚å¸¸ç±»å‹ç”Ÿæˆå»ºè®®
        anomaly_types = [a.get('type', '') for a in anomalies]
        
        if 'cpu_threshold_exceeded' in anomaly_types:
            recommendations.append("CPUä½¿ç”¨ç‡å¼‚å¸¸ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½å’Œè¿›ç¨‹èµ„æºä½¿ç”¨æƒ…å†µ")
        
        if 'memory_threshold_exceeded' in anomaly_types:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡å¼‚å¸¸ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼å’Œä¼˜åŒ–å†…å­˜é…ç½®")
        
        if 'log_pattern_match' in anomaly_types:
            recommendations.append("æ—¥å¿—å¼‚å¸¸æ¨¡å¼æ£€æµ‹ï¼Œå»ºè®®æ£€æŸ¥æœåŠ¡é…ç½®å’Œé”™è¯¯æ—¥å¿—")
        
        if 'pattern_rule_triggered' in anomaly_types:
            recommendations.append("è§¦å‘å¼‚å¸¸æ¨¡å¼è§„åˆ™ï¼Œå»ºè®®æ ¹æ®è§„åˆ™æè¿°è¿›è¡Œç›¸åº”å¤„ç†")
        
        # é€šç”¨å»ºè®®
        if len(anomalies) > 5:
            recommendations.append("æ£€æµ‹åˆ°å¤šä¸ªå¼‚å¸¸ï¼Œå»ºè®®è¿›è¡Œå…¨é¢çš„ç³»ç»Ÿå¥åº·æ£€æŸ¥")
        
        return recommendations


def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰«æå™¨"""
    scanner = {{ class_name }}Scanner()
    
    try:
        results = scanner.run_scan()
        
        # è¾“å‡ºç»“æœ
        print(json.dumps(results, ensure_ascii=False, indent=2))
        
        # è¾“å‡ºæ‘˜è¦
        summary = results.get('summary', {})
        print(f"\\nğŸ“Š æ‰«ææ‘˜è¦:")
        print(f"  çŠ¶æ€: {summary.get('status', 'unknown')}")
        print(f"  å¼‚å¸¸æ•°: {summary.get('total_anomalies', 0)}")
        print(f"  ä¸¥é‡åº¦è¯„åˆ†: {summary.get('severity_score', 0)}")
        print(f"  æ¨¡å¼åŒ¹é…: {summary.get('pattern_matches', 0)}")
        
        if 'recommendations' in summary:
            print(f"\\nğŸ’¡ å»ºè®®:")
            for rec in summary['recommendations']:
                print(f"  - {rec}")
        
        # ä¿å­˜æ‰«æç»“æœåˆ°æ–‡ä»¶
        try:
            import os
            from pathlib import Path
            
            # ç¡®ä¿resultsç›®å½•å­˜åœ¨
            results_dir = Path(__file__).parent / "results"
            results_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"scan_results_{{ service_name }}_{timestamp}.json"
            filepath = results_dir / filename
            
            # ä¿å­˜ç»“æœ
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"\\nğŸ’¾ æ‰«æç»“æœå·²ä¿å­˜åˆ°: {filepath}")
            
        except Exception as save_error:
            print(f"âš ï¸ ä¿å­˜æ‰«æç»“æœå¤±è´¥: {save_error}")
        
    except Exception as e:
        print(f"âŒ æ‰«æå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
'''
        
        return templates
    
    def load_patterns(self) -> Dict[str, Any]:
        """åŠ è½½å¼‚å¸¸æ¨¡å¼"""
        try:
            if not self.patterns_file.exists():
                self.logger.warning("æ¨¡å¼æ–‡ä»¶ä¸å­˜åœ¨")
                return {}
            
            with open(self.patterns_file, 'r', encoding='utf-8') as f:
                patterns = json.load(f)
            
            self.logger.info("å¼‚å¸¸æ¨¡å¼åŠ è½½æˆåŠŸ")
            return patterns
            
        except Exception as e:
            self.logger.error(f"åŠ è½½æ¨¡å¼å¤±è´¥: {e}")
            return {}
    
    def generate_scanner_for_pattern(self, pattern: Dict[str, Any]) -> str:
        """ä¸ºå•ä¸ªæ¨¡å¼ç”Ÿæˆæ‰«æå™¨ä»£ç """
        try:
            # å‡†å¤‡æ¨¡æ¿å˜é‡
            service_name = pattern.get('service', 'unknown')
            class_name = ''.join(word.capitalize() for word in service_name.split('_'))
            
            # å¤„ç†é˜ˆå€¼
            thresholds = {}
            if 'metrics' in pattern:
                for metric_type, metric_data in pattern['metrics'].items():
                    if isinstance(metric_data, dict) and 'mean' in metric_data:
                        # è®¾ç½®é˜ˆå€¼ä¸ºå‡å€¼ + æ ‡å‡†å·®
                        threshold = metric_data.get('mean', 50) + metric_data.get('std', 10)
                        thresholds[metric_type] = round(threshold, 2)
            
            # å¤„ç†æ—¥å¿—å…³é”®è¯ - æ”¯æŒå¤šç§æ¨¡å¼ç±»å‹
            error_keywords = []
            if 'logs' in pattern and 'keywords' in pattern['logs']:
                keywords_data = pattern['logs']['keywords']
                if isinstance(keywords_data, list):
                    error_keywords = [kw.get('keyword', kw) if isinstance(kw, dict) else kw 
                                    for kw in keywords_data[:10]]  # æœ€å¤š10ä¸ªå…³é”®è¯
            elif 'top_keywords' in pattern:  # æ—¥å¿—æ¨¡å¼
                keywords_data = pattern.get('top_keywords', [])
                if isinstance(keywords_data, list):
                    error_keywords = [kw.get('keyword', kw) if isinstance(kw, dict) else kw 
                                    for kw in keywords_data[:10]]  # æœ€å¤š10ä¸ªå…³é”®è¯
            
            # è®¾ç½®é»˜è®¤æ—¥å¿—è·¯å¾„
            log_paths = self._get_default_log_paths(service_name)
            
            # ç”Ÿæˆæ£€æµ‹è§„åˆ™
            detection_rules = self._generate_detection_rules(pattern)
            
            # æ¸²æŸ“æ¨¡æ¿
            template = Template(self.scanner_templates['base_scanner'])
            
            scanner_code = template.render(
                service_name=service_name,
                class_name=class_name,
                pattern_id=pattern.get('pattern_id', 'unknown'),
                generation_time=datetime.now().isoformat(),
                severity=pattern.get('severity', 'medium'),
                confidence=pattern.get('confidence', 0.7),
                thresholds=json.dumps(thresholds, indent=8),
                error_keywords=json.dumps(error_keywords, indent=8),
                log_paths=json.dumps(log_paths, indent=8),
                detection_rules=detection_rules
            )
            
            return scanner_code
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ‰«æå™¨ä»£ç å¤±è´¥: {e}")
            return ""
    
    def _get_default_log_paths(self, service_name: str) -> List[str]:
        """è·å–æœåŠ¡çš„é»˜è®¤æ—¥å¿—è·¯å¾„"""
        log_paths = []
        
        # æ ¹æ®æœåŠ¡åæ¨æ–­æ—¥å¿—è·¯å¾„
        if 'nginx' in service_name.lower():
            log_paths = [
                '/var/log/nginx/error.log',
                '/var/log/nginx/access.log',
                'C:/nginx/logs/error.log'
            ]
        elif 'mysql' in service_name.lower():
            log_paths = [
                '/var/log/mysql/error.log',
                '/var/log/mysqld.log',
                'C:/ProgramData/MySQL/MySQL Server 8.0/Data/mysqld.log'
            ]
        elif 'apache' in service_name.lower():
            log_paths = [
                '/var/log/apache2/error.log',
                '/var/log/httpd/error_log',
                'C:/Apache24/logs/error.log'
            ]
        elif 'redis' in service_name.lower():
            log_paths = [
                '/var/log/redis/redis-server.log',
                'C:/Redis/logs/redis.log'
            ]
        elif 'postgresql' in service_name.lower():
            log_paths = [
                '/var/log/postgresql/postgresql.log',
                'C:/Program Files/PostgreSQL/data/log/postgresql.log'
            ]
        else:
            # é€šç”¨æ—¥å¿—è·¯å¾„
            log_paths = [
                f'/var/log/{service_name}.log',
                f'C:/logs/{service_name}.log'
            ]
        
        return log_paths
    
    def _generate_detection_rules(self, pattern: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ£€æµ‹è§„åˆ™"""
        rules = []
        
        # ä»æ¡ä»¶ä¸­ç”Ÿæˆè§„åˆ™
        conditions = pattern.get('conditions', {})
        condition_rules = conditions.get('rules', [])
        
        for i, rule in enumerate(condition_rules):
            metric = rule.get('metric', '')
            operator = rule.get('operator', '>')
            value = rule.get('value', 0)
            weight = rule.get('weight', 0.5)
            
            # æ„å»ºæ¡ä»¶å­—ç¬¦ä¸²
            if metric == 'log_keywords':
                condition = f"any(keyword.lower() in line.lower() for keyword in self.error_keywords)"
                description = f"æ£€æµ‹åˆ°æ—¥å¿—å…³é”®è¯: {value}"
            else:
                condition = f"metrics.get('{metric}', 0) {operator} {value}"
                description = f"{metric} {operator} {value}"
            
            rules.append({
                'name': f'rule_{i+1}',
                'metric': f"metrics.get('{metric}', 0)",
                'condition': condition,
                'threshold': value,
                'description': description,
                'severity': 'high' if weight > 0.7 else 'medium'
            })
        
        # ä¸ºæ—¥å¿—æ¨¡å¼ç”Ÿæˆé»˜è®¤è§„åˆ™
        if pattern.get('pattern_type') == 'log_anomaly':
            error_count = pattern.get('error_count', 0)
            error_rate = pattern.get('error_rate', 0.0)
            
            # é”™è¯¯æ•°é‡è§„åˆ™
            if error_count > 0:
                rules.append({
                    'name': 'error_count_rule',
                    'metric': 'error_count',
                    'condition': f"error_count > {max(1, error_count // 2)}",
                    'threshold': max(1, error_count // 2),
                    'description': f"é”™è¯¯æ•°é‡è¶…è¿‡é˜ˆå€¼: {max(1, error_count // 2)}",
                    'severity': pattern.get('severity', 'medium')
                })
            
            # é”™è¯¯ç‡è§„åˆ™
            if error_rate > 0:
                rules.append({
                    'name': 'error_rate_rule',
                    'metric': 'error_rate',
                    'condition': f"error_rate > {error_rate * 0.5}",
                    'threshold': error_rate * 0.5,
                    'description': f"é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼: {error_rate * 0.5:.2%}",
                    'severity': pattern.get('severity', 'medium')
                })
        
        return rules
    
    def generate_all_scanners(self) -> Dict[str, str]:
        """ç”Ÿæˆæ‰€æœ‰æ‰«æå™¨"""
        self.logger.info("å¼€å§‹ç”Ÿæˆæ‰«æå™¨...")
        
        # åŠ è½½æ¨¡å¼
        patterns_data = self.load_patterns()
        
        if not patterns_data:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„æ¨¡å¼æ•°æ®")
            return {}
        
        generated_scanners = {}
        
        # æŒ‰æœåŠ¡åˆ†ç»„æ¨¡å¼
        service_patterns = self._group_patterns_by_service(patterns_data)
        
        # ä¸ºæ¯ä¸ªæœåŠ¡ç”Ÿæˆä¸“é—¨çš„æ‰«æå™¨
        for service_name, patterns in service_patterns.items():
            scanner_code = self.generate_service_scanner(service_name, patterns)
            
            if scanner_code:
                scanner_filename = f"scan_{service_name}.py"
                generated_scanners[scanner_filename] = scanner_code
                self.logger.info(f"ä¸º {service_name} ç”Ÿæˆä¸“é—¨æ‰«æå™¨: {scanner_filename}")
        
        return generated_scanners
    
    def _group_patterns_by_service(self, patterns_data: Dict[str, Any]) -> Dict[str, Dict[str, List]]:
        """æŒ‰æœåŠ¡åˆ†ç»„æ¨¡å¼"""
        service_patterns = {}
        
        # å¤„ç†å¤åˆæ¨¡å¼
        composite_patterns = patterns_data.get('composite_patterns', [])
        for pattern in composite_patterns:
            service_name = pattern.get('service', 'unknown')
            if service_name not in service_patterns:
                service_patterns[service_name] = {'composite': [], 'metric': [], 'log': []}
            service_patterns[service_name]['composite'].append(pattern)
        
        # å¤„ç†æŒ‡æ ‡æ¨¡å¼
        metric_patterns = patterns_data.get('metric_patterns', [])
        for pattern in metric_patterns:
            service_name = pattern.get('service', 'unknown')
            if service_name not in service_patterns:
                service_patterns[service_name] = {'composite': [], 'metric': [], 'log': []}
            service_patterns[service_name]['metric'].append(pattern)
        
        # å¤„ç†æ—¥å¿—æ¨¡å¼
        log_patterns = patterns_data.get('log_patterns', [])
        for pattern in log_patterns:
            service_name = pattern.get('service', 'unknown')
            if service_name not in service_patterns:
                service_patterns[service_name] = {'composite': [], 'metric': [], 'log': []}
            service_patterns[service_name]['log'].append(pattern)
        
        return service_patterns
    
    def generate_service_scanner(self, service_name: str, patterns: Dict[str, List]) -> str:
        """ä¸ºç‰¹å®šæœåŠ¡ç”Ÿæˆä¸“é—¨çš„æ‰«æå™¨"""
        try:
            # å‡†å¤‡æ¨¡æ¿å˜é‡
            class_name = ''.join(word.capitalize() for word in service_name.split('_'))
            
            # åˆå¹¶æ‰€æœ‰æ¨¡å¼çš„æ£€æµ‹è§„åˆ™
            all_detection_rules = []
            all_thresholds = {}
            all_error_keywords = []
            
            # å¤„ç†å¤åˆæ¨¡å¼
            for pattern in patterns.get('composite', []):
                rules = self._generate_detection_rules(pattern)
                all_detection_rules.extend(rules)
                
                # åˆå¹¶é˜ˆå€¼
                if 'thresholds' in pattern:
                    all_thresholds.update(pattern['thresholds'])
                
                # åˆå¹¶å…³é”®è¯
                if 'error_keywords' in pattern:
                    all_error_keywords.extend(pattern['error_keywords'])
            
            # å¤„ç†æŒ‡æ ‡æ¨¡å¼
            for pattern in patterns.get('metric', []):
                rules = self._generate_detection_rules(pattern)
                all_detection_rules.extend(rules)
                
                # åˆå¹¶é˜ˆå€¼
                if 'metrics' in pattern:
                    for metric_type, metric_data in pattern['metrics'].items():
                        if isinstance(metric_data, dict) and 'mean' in metric_data:
                            threshold = metric_data.get('mean', 50) + metric_data.get('std', 10)
                            all_thresholds[metric_type] = round(threshold, 2)
            
            # å¤„ç†æ—¥å¿—æ¨¡å¼
            for pattern in patterns.get('log', []):
                rules = self._generate_detection_rules(pattern)
                all_detection_rules.extend(rules)
                
                # åˆå¹¶å…³é”®è¯
                if 'top_keywords' in pattern:
                    keywords_data = pattern.get('top_keywords', [])
                    if isinstance(keywords_data, list):
                        keywords = [kw.get('keyword', kw) if isinstance(kw, dict) else kw 
                                  for kw in keywords_data[:10]]
                        all_error_keywords.extend(keywords)
            
            # å»é‡
            all_error_keywords = list(set(all_error_keywords))
            
            # è®¾ç½®é»˜è®¤æ—¥å¿—è·¯å¾„
            log_paths = self._get_default_log_paths(service_name)
            
            # æ¸²æŸ“æ¨¡æ¿
            template = Template(self.scanner_templates['base_scanner'])
            
            scanner_code = template.render(
                service_name=service_name,
                class_name=class_name,
                pattern_id=f"{service_name}_comprehensive",
                generation_time=datetime.now().isoformat(),
                severity=self._determine_overall_severity(patterns),
                confidence=self._calculate_overall_confidence(patterns),
                thresholds=json.dumps(all_thresholds, indent=8),
                error_keywords=json.dumps(all_error_keywords, indent=8),
                log_paths=json.dumps(log_paths, indent=8),
                detection_rules=all_detection_rules
            )
            
            return scanner_code
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆ {service_name} æ‰«æå™¨å¤±è´¥: {e}")
            return ""
    
    def _determine_overall_severity(self, patterns: Dict[str, List]) -> str:
        """ç¡®å®šæ•´ä½“ä¸¥é‡ç¨‹åº¦"""
        severities = []
        
        for pattern_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                severity = pattern.get('severity', 'medium')
                severities.append(severity)
        
        if not severities:
            return 'medium'
        
        # å¦‚æœæœ‰ä»»ä½•ä¸¥é‡å¼‚å¸¸ï¼Œè¿”å›ä¸¥é‡
        if 'critical' in severities:
            return 'critical'
        elif 'high' in severities:
            return 'high'
        elif 'medium' in severities:
            return 'medium'
        else:
            return 'low'
    
    def _calculate_overall_confidence(self, patterns: Dict[str, List]) -> float:
        """è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦"""
        confidences = []
        
        for pattern_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                confidence = pattern.get('confidence', 0.7)
                confidences.append(confidence)
        
        if not confidences:
            return 0.7
        
        return round(sum(confidences) / len(confidences), 2)
    
    def save_scanners(self, scanners: Dict[str, str]):
        """ä¿å­˜ç”Ÿæˆçš„æ‰«æå™¨æ–‡ä»¶"""
        try:
            for filename, code in scanners.items():
                scanner_path = self.scanners_dir / filename
                
                with open(scanner_path, 'w', encoding='utf-8') as f:
                    f.write(code)
                
                # è®¾ç½®å¯æ‰§è¡Œæƒé™ï¼ˆUnixç³»ç»Ÿï¼‰
                try:
                    scanner_path.chmod(0o755)
                except (AttributeError, OSError):
                    pass  # Windowsç³»ç»Ÿæˆ–æƒé™è®¾ç½®å¤±è´¥
                
                self.logger.info(f"æ‰«æå™¨å·²ä¿å­˜: {scanner_path}")
            
            # ç”Ÿæˆæ‰«æå™¨ç´¢å¼•æ–‡ä»¶
            self._generate_scanner_index(list(scanners.keys()))
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ‰«æå™¨å¤±è´¥: {e}")
    
    def _generate_scanner_index(self, scanner_files: List[str]):
        """ç”Ÿæˆæ‰«æå™¨ç´¢å¼•æ–‡ä»¶"""
        index_content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰«æå™¨ç´¢å¼• - ç®¡ç†æ‰€æœ‰ç”Ÿæˆçš„æ‰«æå™¨
ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}
"""

import subprocess
import sys
from pathlib import Path


def run_scanner(scanner_name: str):
    """è¿è¡ŒæŒ‡å®šçš„æ‰«æå™¨"""
    scanner_path = Path(__file__).parent / f"{{scanner_name}}.py"
    
    if not scanner_path.exists():
        print(f"âŒ æ‰«æå™¨ä¸å­˜åœ¨: {{scanner_path}}")
        return False
    
    try:
        result = subprocess.run([sys.executable, str(scanner_path)], 
                              capture_output=True, text=True)
        
        print(result.stdout)
        if result.stderr:
            print(f"é”™è¯¯: {{result.stderr}}")
        
        return result.returncode == 0
        
    except Exception as e:
        print(f"âŒ è¿è¡Œæ‰«æå™¨å¤±è´¥: {{e}}")
        return False


def run_all_scanners():
    """è¿è¡Œæ‰€æœ‰æ‰«æå™¨"""
    scanners = {scanner_files}
    
    print(f"ğŸ” å¼€å§‹è¿è¡Œ {{len(scanners)}} ä¸ªæ‰«æå™¨...")
    
    success_count = 0
    for scanner in scanners:
        scanner_name = scanner.replace('.py', '')
        print(f"\\n{'='*50}")
        print(f"è¿è¡Œæ‰«æå™¨: {{scanner_name}}")
        print(f"{'='*50}")
        
        if run_scanner(scanner_name):
            success_count += 1
    
    print(f"\\nğŸ“Š æ‰«æå®Œæˆ: {{success_count}}/{{len(scanners)}} ä¸ªæ‰«æå™¨æˆåŠŸè¿è¡Œ")


def list_scanners():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ‰«æå™¨"""
    scanners = {scanner_files}
    
    print("ğŸ“‹ å¯ç”¨çš„æ‰«æå™¨:")
    for i, scanner in enumerate(scanners, 1):
        scanner_name = scanner.replace('.py', '').replace('scan_', '')
        print(f"  {{i}}. {{scanner_name}} ({{scanner}})")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python scanner_index.py list           # åˆ—å‡ºæ‰€æœ‰æ‰«æå™¨")
        print("  python scanner_index.py run <name>     # è¿è¡ŒæŒ‡å®šæ‰«æå™¨")
        print("  python scanner_index.py run-all        # è¿è¡Œæ‰€æœ‰æ‰«æå™¨")
        return
    
    command = sys.argv[1]
    
    if command == 'list':
        list_scanners()
    elif command == 'run' and len(sys.argv) > 2:
        scanner_name = sys.argv[2]
        run_scanner(scanner_name)
    elif command == 'run-all':
        run_all_scanners()
    else:
        print("âŒ æ— æ•ˆçš„å‘½ä»¤")


if __name__ == "__main__":
    main()
'''
        
        index_path = self.scanners_dir / "scanner_index.py"
        
        try:
            with open(index_path, 'w', encoding='utf-8') as f:
                f.write(index_content)
            
            # è®¾ç½®å¯æ‰§è¡Œæƒé™
            try:
                index_path.chmod(0o755)
            except (AttributeError, OSError):
                pass
            
            self.logger.info(f"æ‰«æå™¨ç´¢å¼•å·²ä¿å­˜: {index_path}")
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ‰«æå™¨ç´¢å¼•å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°æ¼”ç¤º"""
    generator = ScannerGenerator(output_dir="data", scanners_dir="/home/denerate/abnormal_pattern_detect/scanners")
    
    print("ğŸ”§ å¼€å§‹ç”Ÿæˆæ‰«æå™¨...")
    
    try:
        # ç”Ÿæˆæ‰€æœ‰æ‰«æå™¨
        scanners = generator.generate_all_scanners()
        
        if not scanners:
            print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ‰«æå™¨ï¼Œè¯·å…ˆè¿è¡Œæ¨¡å¼æå–")
            return
        
        # ä¿å­˜æ‰«æå™¨æ–‡ä»¶
        generator.save_scanners(scanners)
        
        # æ˜¾ç¤ºæ‘˜è¦
        print(f"\nğŸ“Š æ‰«æå™¨ç”Ÿæˆæ‘˜è¦:")
        print(f"  - ç”Ÿæˆæ‰«æå™¨æ•°é‡: {len(scanners)}")
        print(f"  - ä¿å­˜ç›®å½•: {generator.scanners_dir}")
        
        print(f"\nğŸ”§ ç”Ÿæˆçš„æ‰«æå™¨:")
        for filename in scanners.keys():
            service_name = filename.replace('scan_', '').replace('.py', '')
            print(f"  - {service_name}: {filename}")
        
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print(f"  cd {generator.scanners_dir}")
        print(f"  python scanner_index.py list      # æŸ¥çœ‹æ‰€æœ‰æ‰«æå™¨")
        print(f"  python scanner_index.py run-all   # è¿è¡Œæ‰€æœ‰æ‰«æå™¨")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ‰«æå™¨å¤±è´¥: {e}")


if __name__ == "__main__":
    main() 